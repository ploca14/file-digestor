{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "with open('docs.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "docs = data['processed_data']\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_docs(docs):\n",
    "    \"\"\"Combine document chunks into markdown formatted string based on element type\"\"\"\n",
    "    formatted_chunks = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        content = doc[\"page_content\"]\n",
    "        category = doc[\"metadata\"].get(\"category\", \"UncategorizedText\")\n",
    "        \n",
    "        # Format based on element type\n",
    "        if category == \"Title\":\n",
    "            formatted = f\"## {content}\"\n",
    "        elif category == \"Header\":\n",
    "            formatted = f\"# {content}\"\n",
    "        elif category == \"ListItem\":\n",
    "            formatted = f\"* {content}\"\n",
    "        elif category == \"FigureCaption\":\n",
    "            formatted = f\"*Figure: {content}*\"\n",
    "        elif category == \"Formula\":\n",
    "            formatted = f\"```math\\n{content}\\n```\"\n",
    "        elif category == \"CodeSnippet\":\n",
    "            formatted = f\"```\\n{content}\\n```\"\n",
    "        elif category == \"Table\":\n",
    "            # Tables might need more complex handling depending on structure\n",
    "            formatted = f\"| {content} |\"\n",
    "        elif category in [\"Footer\", \"PageNumber\"]:\n",
    "            # Skip footer and page numbers\n",
    "            continue\n",
    "        else:\n",
    "            # Default handling for NarrativeText and other types\n",
    "            formatted = content\n",
    "            \n",
    "        formatted_chunks.append(formatted)\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_chunks)\n",
    "\n",
    "# Process the PDF\n",
    "text = combine_docs(docs)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal, Optional, Union\n",
    "\n",
    "# Base FHIR Models\n",
    "class Quantity(BaseModel):\n",
    "    value: Optional[float] = None \n",
    "    comparator: Optional[Literal[\"<\", \"<=\", \">=\", \">\", \"ad\"]] = None  # How to understand the value\n",
    "    unit: Optional[str] = None \n",
    "    system: Optional[str] = None \n",
    "    code: Optional[str] = None\n",
    "\n",
    "class Coding(BaseModel):\n",
    "    system: str\n",
    "    code: str\n",
    "    display: Optional[str] = None\n",
    "\n",
    "class CodeableConcept(BaseModel):\n",
    "    coding: List[Coding] = Field(default_factory=list)\n",
    "    text: Optional[str] = None\n",
    "\n",
    "class Identifier(BaseModel):\n",
    "    system: Optional[str] = None\n",
    "    value: str\n",
    "\n",
    "class HumanName(BaseModel):\n",
    "    text: Optional[str] = None\n",
    "    family: Optional[str] = None\n",
    "    given: Optional[List[str]] = Field(default_factory=list)\n",
    "    prefix: Optional[List[str]] = Field(default_factory=list)\n",
    "    suffix: Optional[List[str]] = Field(default_factory=list)\n",
    "\n",
    "class Address(BaseModel):\n",
    "    text: Optional[str] = None\n",
    "    line: Optional[List[str]] = Field(default_factory=list)\n",
    "    city: Optional[str] = None\n",
    "    state: Optional[str] = None\n",
    "    postalCode: Optional[str] = None\n",
    "    country: Optional[str] = None\n",
    "\n",
    "class Dosage(BaseModel):\n",
    "    text: Optional[str] = None\n",
    "    timing: Optional[CodeableConcept] = None\n",
    "    route: Optional[CodeableConcept] = None\n",
    "    method: Optional[CodeableConcept] = None\n",
    "\n",
    "# FHIR Resources\n",
    "class Patient(BaseModel):\n",
    "    resourceType: Literal[\"Patient\"] = \"Patient\"\n",
    "    identifier: Optional[List[Identifier]] = Field(default_factory=list)\n",
    "    name: Optional[List[HumanName]] = Field(default_factory=list)\n",
    "    gender: Optional[Literal[\"male\", \"female\", \"other\", \"unknown\"]] = None\n",
    "    birthDate: Optional[str] = None\n",
    "    address: Optional[List[Address]] = Field(default_factory=list)\n",
    "\n",
    "class Observation(BaseModel):\n",
    "    resourceType: Literal[\"Observation\"] = \"Observation\"\n",
    "    identifier: Optional[List[Identifier]] = Field(default_factory=list)\n",
    "    status: Literal[\"registered\", \"preliminary\", \"final\", \"amended\", \"corrected\", \"cancelled\", \"entered-in-error\", \"unknown\"]\n",
    "    code: CodeableConcept\n",
    "    effectiveDateTime: Optional[str] = None\n",
    "    valueQuantity: Optional[Quantity] = None  # For numeric measurements\n",
    "\n",
    "class Condition(BaseModel):\n",
    "    resourceType: Literal[\"Condition\"] = \"Condition\"\n",
    "    identifier: Optional[List[Identifier]] = Field(default_factory=list)\n",
    "    clinicalStatus: CodeableConcept\n",
    "    code: CodeableConcept\n",
    "    onsetDateTime: Optional[str] = None\n",
    "\n",
    "class MedicationStatement(BaseModel):\n",
    "    resourceType: Literal[\"MedicationStatement\"] = \"MedicationStatement\"\n",
    "    identifier: Optional[List[Identifier]] = Field(default_factory=list)\n",
    "    status: Literal[\"recorded\", \"entered-in-error\", \"draft\"]\n",
    "    medicationCodeableConcept: Optional[CodeableConcept] = None\n",
    "    effectiveDateTime: Optional[str] = None\n",
    "    dosage: Optional[List[Dosage]] = Field(default_factory=list)\n",
    "\n",
    "class Bundle(BaseModel):\n",
    "    resourceType: Literal[\"Bundle\"] = \"Bundle\"\n",
    "    type: Literal[\"document\"]\n",
    "    timestamp: str\n",
    "    coding: List[Coding] = Field(default_factory=list)\n",
    "    entry: List[Union[Patient, Observation, Condition, MedicationStatement]] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def create_fhir_extraction_chain():\n",
    "    \"\"\"Create an LLM chain for extracting FHIR data\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an expert at converting medical documents into HL7 FHIR resources.\n",
    "        Extract all relevant clinical information and structure it according to FHIR R4 standards.\n",
    "        \n",
    "        Important guidelines:\n",
    "        - Ensure all required FHIR fields are populated\n",
    "        - Use standard FHIR codings (LOINC, SNOMED CT, etc.) where applicable\n",
    "        - Include proper status and category fields for observations\n",
    "        - Generate unique UUIDs for all resources\n",
    "        - Link observations to the patient using proper references\n",
    "        - Include dates and times when available\n",
    "        - Only extract information explicitly stated in the source\n",
    "        - Try to extract as much information as possible.\n",
    "        - Try to fill in all optional fields.\n",
    "        - Try to keep the format as close to the original as possible.\n",
    "        - Keep the original language.\n",
    "        \"\"\"),\n",
    "        (\"human\", \"Medical Report:\\n{text}\")\n",
    "    ])\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    return prompt | llm.with_structured_output(schema=Bundle, method=\"json_schema\", strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_fhir_extraction_chain()\n",
    "\n",
    "bundle = chain.invoke({\"text\": text})\n",
    "bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bundle.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainText(BaseModel):\n",
    "    text: str\n",
    "\n",
    "def create_plain_text_extraction_chain():\n",
    "    \"\"\"Create an LLM chain for extracting plain text medical information\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an expert at extracting relevant medical information from documents.\n",
    "        Convert the markdown-formatted medical report into clean plaintext while:\n",
    "        \n",
    "        - Preserve all important medical information including:\n",
    "          - Patient details\n",
    "          - Diagnoses\n",
    "          - Medications\n",
    "          - Test results\n",
    "          - Treatment plans\n",
    "          - Clinical observations\n",
    "        - Keep original medical terminology and exact values\n",
    "        - Maintain the original sentence structure where possible\n",
    "        - Remove formatting markers, headers, footers, page numbers\n",
    "        - Skip administrative metadata\n",
    "        - Present information in a clear, readable format\n",
    "        - Preserve the logical flow of information\n",
    "        - Keep the text as close to the original as possible.\n",
    "        - Keep the original language.\n",
    "        \n",
    "        Return only the essential medical content in plain text format.\n",
    "        \"\"\"),\n",
    "        (\"human\", \"{text}\")\n",
    "    ])\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    return prompt | llm.with_structured_output(schema=PlainText, method=\"json_schema\", strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_text_chain = create_plain_text_extraction_chain()\n",
    "plain_text = plain_text_chain.invoke({\"text\": text})\n",
    "print(plain_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plain_text.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plain_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "fhir_extraction_chain = create_fhir_extraction_chain()\n",
    "plain_text_chain = create_plain_text_extraction_chain()\n",
    "\n",
    "extraction_chains = RunnableParallel(\n",
    "    fhir=fhir_extraction_chain,\n",
    "    plain_text=plain_text_chain\n",
    ")\n",
    "\n",
    "results = extraction_chains.invoke({\"text\": text})\n",
    "print(\"FHIR Bundle:\")\n",
    "print(results[\"fhir\"])\n",
    "print(\"\\nPlain Text:\")\n",
    "print(results[\"plain_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
