{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('docs.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "docs = data['processed_data']\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_docs(docs):\n",
    "    \"\"\"Combine document chunks into markdown formatted string based on element type\"\"\"\n",
    "    formatted_chunks = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        content = doc[\"page_content\"]\n",
    "        category = doc[\"metadata\"].get(\"category\", \"UncategorizedText\")\n",
    "        \n",
    "        # Format based on element type\n",
    "        if category == \"Title\":\n",
    "            formatted = f\"## {content}\"\n",
    "        elif category == \"Header\":\n",
    "            formatted = f\"# {content}\"\n",
    "        elif category == \"ListItem\":\n",
    "            formatted = f\"* {content}\"\n",
    "        elif category == \"FigureCaption\":\n",
    "            formatted = f\"*Figure: {content}*\"\n",
    "        elif category == \"Formula\":\n",
    "            formatted = f\"```math\\n{content}\\n```\"\n",
    "        elif category == \"CodeSnippet\":\n",
    "            formatted = f\"```\\n{content}\\n```\"\n",
    "        elif category == \"Table\":\n",
    "            # Tables might need more complex handling depending on structure\n",
    "            formatted = f\"| {content} |\"\n",
    "        elif category in [\"Footer\", \"PageNumber\"]:\n",
    "            # Skip footer and page numbers\n",
    "            continue\n",
    "        else:\n",
    "            # Default handling for NarrativeText and other types\n",
    "            formatted = content\n",
    "            \n",
    "        formatted_chunks.append(formatted)\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_chunks)\n",
    "\n",
    "# Process the PDF\n",
    "text = combine_docs(docs)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from fhir.resources.patient import Patient\n",
    "from fhir.resources.observation import Observation\n",
    "from fhir.resources.bundle import Bundle\n",
    "from fhir.resources.fhirtypes import BundleEntryType\n",
    "\n",
    "def combine_docs(docs):\n",
    "    \"\"\"Combine document chunks into a single text while preserving structure\"\"\"\n",
    "    formatted_chunks = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        content = doc[\"page_content\"]\n",
    "        category = doc[\"metadata\"].get(\"category\", \"UncategorizedText\")\n",
    "        formatted_chunks.append(f\"{category}: {content}\")\n",
    "            \n",
    "    return \"\\n\\n\".join(formatted_chunks)\n",
    "\n",
    "def create_fhir_extraction_chain():\n",
    "    \"\"\"Create an LLM chain for extracting FHIR data\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an expert at converting medical documents into HL7 FHIR resources.\n",
    "        Extract all relevant clinical information and structure it according to FHIR R5 standards.\n",
    "        Only include information that is explicitly stated in the source document.\n",
    "        Return a JSON object with separate 'patient','observations','conditions','medicationStatements' keys.\"\"\"),\n",
    "        (\"human\", \"Medical Report:\\n{text}\")\n",
    "    ])\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    return prompt | llm.with_structured_output({\n",
    "        \"title\": \"MedicalExtraction\",\n",
    "        \"description\": \"Extract patient and observation data from medical text\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"patient\": {\n",
    "                \"type\": \"object\",\n",
    "                \"description\": \"Patient information\"\n",
    "            },\n",
    "            \"observations\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"List of observations\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\"\n",
    "                }\n",
    "            },\n",
    "            \"conditions\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"List of conditions\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\"\n",
    "                }\n",
    "            },\n",
    "            \"medicationStatements\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"List of medication statements\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    })\n",
    "\n",
    "def create_fhir_bundle(extracted_data):\n",
    "    \"\"\"Convert extracted data into a FHIR Bundle\"\"\"\n",
    "    # Create Patient resource\n",
    "    patient = Patient.parse_obj(extracted_data[\"patient\"])\n",
    "    \n",
    "    # Create Observation resources\n",
    "    observations = [\n",
    "        Observation.parse_obj(obs) for obs in extracted_data[\"observations\"]\n",
    "    ]\n",
    "    \n",
    "    # Create Bundle\n",
    "    bundle = Bundle()\n",
    "    bundle.type = \"collection\"\n",
    "    bundle.entry = []\n",
    "    \n",
    "    # Add patient to bundle\n",
    "    bundle.entry.append({\n",
    "        \"resource\": patient.dict(),\n",
    "        \"fullUrl\": f\"urn:uuid:{patient.id}\",\n",
    "    })\n",
    "    \n",
    "    # Add observations to bundle\n",
    "    for obs in observations:\n",
    "        bundle.entry.append({\n",
    "            \"resource\": obs.dict(),\n",
    "            \"fullUrl\": f\"urn:uuid:{obs.id}\",\n",
    "        })\n",
    "    \n",
    "    return bundle\n",
    "\n",
    "# Main processing pipeline\n",
    "def process_medical_report(docs):\n",
    "    # Combine document chunks\n",
    "    text = combine_docs(docs)\n",
    "    \n",
    "    # Extract structured data using LLM\n",
    "    extraction_chain = create_fhir_extraction_chain()\n",
    "    extracted_data = extraction_chain.invoke({\"text\": text})\n",
    "    \n",
    "    # # Create and validate FHIR bundle\n",
    "    # fhir_bundle = create_fhir_bundle(extracted_data)\n",
    "    \n",
    "    # return fhir_bundle\n",
    "    return extracted_data\n",
    "\n",
    "# Use the pipeline\n",
    "# fhir_bundle = process_medical_report(docs)\n",
    "# print(fhir_bundle.json(indent=2))\n",
    "process_medical_report(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fhir_extraction_chain():\n",
    "    \"\"\"Create an LLM chain for extracting FHIR data\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an expert at converting medical documents into HL7 FHIR resources.\n",
    "        Create a FHIR Bundle (R4) containing all relevant clinical information from the medical report.\n",
    "        \n",
    "        Important guidelines:\n",
    "        - Create a Bundle of type \"document\"\n",
    "        - Include a Patient resource as the first entry\n",
    "        - Add Observation resources for measurements and findings\n",
    "        - Add Condition resources for diagnoses\n",
    "        - Add MedicationStatement resources for medications\n",
    "        - Ensure all resources have unique UUIDs\n",
    "        - Use proper FHIR references between resources\n",
    "        - Use standard codings (LOINC, SNOMED CT) where applicable\n",
    "        - Include proper status and category fields\n",
    "        - Only include information explicitly stated in the source\n",
    "        \n",
    "        Return a complete FHIR Bundle as a JSON object with all required fields.\n",
    "        \"\"\"),\n",
    "        (\"human\", \"Medical Report:\\n{text}\")\n",
    "    ])\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    return prompt | llm.with_structured_output({\n",
    "        \"title\": \"MedicalExtraction\",\n",
    "        \"description\": \"Extract patient and observation data from medical text\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"resourceType\": {\"type\": \"string\", \"enum\": [\"Bundle\"]},\n",
    "            \"type\": {\"type\": \"string\", \"enum\": [\"document\"]},\n",
    "            \"entry\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"resource\": {\"type\": \"object\"}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "def process_medical_report(docs):\n",
    "    \"\"\"Process medical report into FHIR Bundle\"\"\"\n",
    "    # Combine document chunks\n",
    "    text = combine_docs(docs)\n",
    "    \n",
    "    # Extract FHIR Bundle using LLM\n",
    "    extraction_chain = create_fhir_extraction_chain()\n",
    "    fhir_bundle = extraction_chain.invoke({\"text\": text})\n",
    "\n",
    "    # Validate the bundle (optional)\n",
    "    # return [fhir_bundle, Bundle.parse_obj(fhir_bundle)]\n",
    "    return fhir_bundle\n",
    "# Use the pipeline\n",
    "raw_bundle = process_medical_report(docs)\n",
    "# print(bundle.json(indent=2))\n",
    "print(raw_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from fhir.resources.R4B.bundle import Bundle\n",
    "\n",
    "\n",
    "with open('bundle.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "Bundle.parse_obj(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
